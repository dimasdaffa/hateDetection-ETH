{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\nino\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\nino\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.15.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nino\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.0-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/11.1 MB 3.1 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.8/11.1 MB 8.0 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.5/11.1 MB 10.5 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.3/11.1 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.6/11.1 MB 12.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.4/11.1 MB 13.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.2/11.1 MB 13.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.2/11.1 MB 14.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.0/11.1 MB 14.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.8/11.1 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.1 MB 15.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.5/11.1 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.5/11.1 MB 17.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.1/11.1 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 16.4 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.0 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Nino\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Distribution:\n",
      "label\n",
      "no-hate    257\n",
      "hate        98\n",
      "Name: count, dtype: int64\n",
      "Balanced Distribution:\n",
      "label\n",
      "no-hate    700\n",
      "hate       300\n",
      "Name: count, dtype: int64\n",
      "Dataset saved as 'Oversampled_Tweet_Dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "# Install missing packages\n",
    "%pip install scikit-learn\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Load dataset\n",
    "file_path = r'C:\\Users\\Nino\\Documents\\hateDetection-ETH\\TweethateETHMU.csv'\n",
    "data_raw = pd.read_csv(file_path, encoding='latin1', on_bad_lines='skip')\n",
    "\n",
    "# Clean column names\n",
    "data_raw.columns = data_raw.columns.str.replace(r'[\";]', '', regex=True)\n",
    "\n",
    "# Select relevant columns\n",
    "data_cleaned = data_raw[['full_text', 'usernamelabel']].copy()\n",
    "data_cleaned.rename(columns={'full_text': 'text', 'usernamelabel': 'label'}, inplace=True)\n",
    "\n",
    "# Extract labels\n",
    "data_cleaned['label'] = data_cleaned['label'].fillna('').astype(str)\n",
    "data_cleaned['label'] = data_cleaned['label'].apply(lambda x: x.split(';')[-1] if ';' in x else x)\n",
    "\n",
    "# Remove duplicates and invalid labels\n",
    "data_cleaned.drop_duplicates(subset='text', inplace=True)\n",
    "data_cleaned = data_cleaned[data_cleaned['label'].isin(['hate', 'no-hate'])]\n",
    "\n",
    "# Check initial class distribution\n",
    "initial_distribution = data_cleaned['label'].value_counts()\n",
    "print(\"Initial Distribution:\")\n",
    "print(initial_distribution)\n",
    "\n",
    "# Separate classes\n",
    "no_hate = data_cleaned[data_cleaned['label'] == 'no-hate']\n",
    "hate = data_cleaned[data_cleaned['label'] == 'hate']\n",
    "\n",
    "# Oversample classes\n",
    "hate_upsampled = resample(hate, replace=True, n_samples=300, random_state=42)\n",
    "no_hate_upsampled = resample(no_hate, replace=True, n_samples=700, random_state=42)\n",
    "\n",
    "# Combine oversampled data\n",
    "data_balanced = pd.concat([no_hate_upsampled, hate_upsampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check balanced distribution\n",
    "balanced_distribution = data_balanced['label'].value_counts()\n",
    "print(\"Balanced Distribution:\")\n",
    "print(balanced_distribution)\n",
    "\n",
    "# Save the oversampled dataset\n",
    "data_balanced.to_csv('Oversampled_Tweet_Dataset.csv', index=False, encoding='utf-8')\n",
    "print(\"Dataset saved as 'Oversampled_Tweet_Dataset.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

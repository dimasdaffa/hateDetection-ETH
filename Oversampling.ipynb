{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi Awal:\n",
      "label\n",
      "no-hate    257\n",
      "hate        98\n",
      "Name: count, dtype: int64\n",
      "Distribusi Setelah Oversampling:\n",
      "label\n",
      "no-hate    700\n",
      "hate       700\n",
      "Name: count, dtype: int64\n",
      "Dataset disimpan sebagai 'Oversampled_Tweet_Dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Installasi library yang dibutuhkan\n",
    "# %pip install scikit-learn\n",
    "\n",
    "# Import library yang diperlukan\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Memuat dataset dari file CSV\n",
    "file_path = r'C:\\Users\\Nino\\Documents\\hateDetection-ETH\\TweethateETHMU.csv'\n",
    "data_raw = pd.read_csv(file_path, encoding='latin1', on_bad_lines='skip')\n",
    "\n",
    "# Membersihkan nama kolom agar tidak ada karakter khusus\n",
    "# seperti tanda kutip (\") atau titik koma (;)\n",
    "data_raw.columns = data_raw.columns.str.replace(r'[\\\";]', '', regex=True)\n",
    "\n",
    "# Memilih kolom yang relevan untuk analisis\n",
    "data_cleaned = data_raw[['full_text', 'usernamelabel']].copy()\n",
    "data_cleaned.rename(columns={'full_text': 'text', 'usernamelabel': 'label'}, inplace=True)\n",
    "\n",
    "# Mengekstrak label dari data\n",
    "# Jika terdapat tanda titik koma (;), hanya mengambil bagian terakhir\n",
    "data_cleaned['label'] = data_cleaned['label'].fillna('').astype(str)\n",
    "data_cleaned['label'] = data_cleaned['label'].apply(lambda x: x.split(';')[-1] if ';' in x else x)\n",
    "\n",
    "# Menghapus data duplikat berdasarkan teks dan label yang tidak valid\n",
    "data_cleaned.drop_duplicates(subset='text', inplace=True)\n",
    "data_cleaned = data_cleaned[data_cleaned['label'].isin(['hate', 'no-hate'])]\n",
    "\n",
    "# Memeriksa distribusi awal kelas pada dataset\n",
    "distribusi_awal = data_cleaned['label'].value_counts()\n",
    "print(\"Distribusi Awal:\")\n",
    "print(distribusi_awal)\n",
    "\n",
    "# Memisahkan data berdasarkan kelas (label)\n",
    "no_hate = data_cleaned[data_cleaned['label'] == 'no-hate']\n",
    "hate = data_cleaned[data_cleaned['label'] == 'hate']\n",
    "\n",
    "# Melakukan oversampling pada kelas yang kurang\n",
    "# Untuk kelas \"hate\", ditambah hingga memiliki 300 sampel\n",
    "# Untuk kelas \"no-hate\", ditambah hingga memiliki 700 sampel\n",
    "hate_upsampled = resample(hate, replace=True, n_samples=700, random_state=42)\n",
    "no_hate_upsampled = resample(no_hate, replace=True, n_samples=700, random_state=42)\n",
    "\n",
    "# Menggabungkan kembali data hasil oversampling\n",
    "data_balanced = pd.concat([no_hate_upsampled, hate_upsampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Memeriksa distribusi data setelah proses oversampling\n",
    "distribusi_seimbang = data_balanced['label'].value_counts()\n",
    "print(\"Distribusi Setelah Oversampling:\")\n",
    "print(distribusi_seimbang)\n",
    "\n",
    "# Menyimpan dataset hasil oversampling ke file CSV\n",
    "data_balanced.to_csv('OversampledV2_Tweet_Dataset.csv', index=False, encoding='utf-8')\n",
    "print(\"Dataset disimpan sebagai 'Oversampled_Tweet_Dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
